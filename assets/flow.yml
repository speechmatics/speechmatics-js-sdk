asyncapi: 3.0.0
id: "urn:com:speechmatics:flow-aservice"
defaultContentType: application/json
info:
  title: Speechmatics Flow API
  version: "1.0.0"
  contact:
    name: Speechmatics Support
    url: https://www.speechmatics.com/product/support/
    email: support@speechmatics.com
  externalDocs:
    description: "Flow API Reference"
    url: https://docs.speechmatics.com/api-ref/flow-voice-ai

servers:
  default:
    host: flow.api.speechmatics.com/v1/flow
    protocol: wss
    protocolVersion: v13 (RFC 6455)
    description: Flow server
    variables:
      ports:
        default: "9000"

channels:
  publish:
    address: /
    messages:
      StartConversation:
        $ref: "#/components/messages/StartConversation"
      AddAudio:
        $ref: "#/components/messages/AddAudio"
      AudioReceived:
        $ref: "#/components/messages/AudioReceived"
      AudioEnded:
        $ref: "#/components/messages/AudioEnded"
      AddInput:
        $ref: "#/components/messages/AddInput"
  subscribe:
    address: /
    messages:
      ConversationStarted:
        $ref: "#/components/messages/ConversationStarted"
      AddAudio:
        $ref: "#/components/messages/AddAudio"
      AudioAdded:
        $ref: "#/components/messages/AudioAdded"
      AddPartialTranscript:
        $ref: "#/components/messages/AddPartialTranscript"
      AddTranscript:
        $ref: "#/components/messages/AddTranscript"
      ResponseStarted:
        $ref: "#/components/messages/ResponseStarted"
      ResponseCompleted:
        $ref: "#/components/messages/ResponseCompleted"
      ResponseInterrupted:
        $ref: "#/components/messages/ResponseInterrupted"
      Error:
        $ref: "#/components/messages/Error"
      Warning:
        $ref: "#/components/messages/Warning"
      Info:
        $ref: "#/components/messages/Info"
      ConversationEnding:
        $ref: "#/components/messages/ConversationEnding"
      ConversationEnded:
        $ref: "#/components/messages/ConversationEnded"

operations:
  publish:
    action: send
    channel:
      $ref: "#/channels/publish"
    messages:
      - $ref: "#/channels/publish/messages/StartConversation"
      - $ref: "#/channels/publish/messages/AddAudio"
      - $ref: "#/channels/publish/messages/AudioReceived"
      - $ref: "#/channels/publish/messages/AudioEnded"
      - $ref: "#/channels/publish/messages/AddInput"
  subscribe:
    action: receive
    channel:
      $ref: "#/channels/subscribe"
    messages:
      - $ref: "#/channels/subscribe/messages/ConversationStarted"
      - $ref: "#/channels/subscribe/messages/AddAudio"
      - $ref: "#/channels/subscribe/messages/AudioAdded"
      - $ref: "#/channels/subscribe/messages/AddPartialTranscript"
      - $ref: "#/channels/subscribe/messages/AddTranscript"
      - $ref: "#/channels/subscribe/messages/ResponseStarted"
      - $ref: "#/channels/subscribe/messages/ResponseCompleted"
      - $ref: "#/channels/subscribe/messages/ResponseInterrupted"
      - $ref: "#/channels/subscribe/messages/Error"
      - $ref: "#/channels/subscribe/messages/Warning"
      - $ref: "#/channels/subscribe/messages/Info"
      - $ref: "#/channels/subscribe/messages/ConversationEnding"
      - $ref: "#/channels/subscribe/messages/ConversationEnded"

components:
  messages:
    StartConversation:
      summary: Initiates a new conversation session.
      payload:
        type: object
        properties:
          message:
            const: StartConversation
          audio_format:
            "$ref": "#/components/schemas/AudioFormat"
          conversation_config:
            "$ref": "#/components/schemas/ConversationConfig"
          debug:
            type: object
            properties:
              llm:
                type: boolean
            additionalProperties: true
          tools:
            type: array
            items:
              "$ref": "#/components/schemas/ToolConfig"
            description: >-
              A list of tools that the LLM can use during the conversation. The
              tools must be defined in the conversation_config.template_variables.
        required:
          - message
          - audio_format
          - conversation_config

    AddAudio:
      summary: A binary chunk of audio. The server confirms receipt by sending an AudioAdded message.
      contentType: application/octet-stream
      payload:
        type: string
        format: binary

    AudioReceived:
      summary: Client response to AddAudio, indicating that server audio has been added to the client successfully.
      payload:
        type: object
        properties:
          message:
            const: AudioReceived
          seq_no:
            type: integer
        required:
          - message
          - seq_no

    AudioEnded:
      summary: Declares that the client has no more audio to send.
      payload:
        type: object
        properties:
          message:
            const: AudioEnded
          last_seq_no:
            type: integer
        required:
          - message
          - last_seq_no

    AddInput:
      summary: Message used by the application client to send input to the LLM in order to influence the conversation.
      payload:
        type: object
        properties:
          message:
            const: AddInput
          input:
            type: string
          interrupt_response:
            type: boolean
            default: false
            description: >-
              If true, the response will be interrupted by the new input. If false,
              the response will continue until it is complete, defaults to false.
          immediate:
            type: boolean
            default: false
            description: >-
              If true, the input will be treated as urgent and will be sent to LLM immediately.
              If false, new input will be added to current prompt and sent to LLM as a part of the next request.
        required:
          - message
          - input

    ConversationStarted:
      summary: Server response to StartConversation, acknowledging that a conversation session has started.
      payload:
        type: object
        properties:
          message:
            const: ConversationStarted
          orchestrator_version:
            type: string
          id:
            type: string
        required:
          - message

    AudioAdded:
      summary: Server response to AddAudio, indicating that audio has been added successfully.
      payload:
        type: object
        properties:
          message:
            const: AudioAdded
          seq_no:
            type: integer
        required:
          - message
          - seq_no

    AddPartialTranscript:
      summary: Contains a work-in-progress transcript of a part of the audio that the client has sent.
      payload:
        type: object
        properties:
          message:
            const: AddPartialTranscript
          format:
            type: string
            example: "2.1"
            description: Speechmatics JSON output format version number.
          metadata:
            "$ref": "#/components/schemas/RecognitionMetadata"
          results:
            type: array
            items:
              "$ref": "#/components/schemas/RecognitionResult"
        required:
          - message
          - metadata
          - results

    AddTranscript:
      summary: Contains the final transcript of a part of the audio that the client has sent.
      payload:
        type: object
        properties:
          message:
            const: AddTranscript
          format:
            type: string
            example: "2.1"
            description: Speechmatics JSON output format version number.
          metadata:
            "$ref": "#/components/schemas/RecognitionMetadata"
          results:
            type: array
            items:
              "$ref": "#/components/schemas/RecognitionResult"
        required:
          - message
          - metadata
          - results

    ResponseStarted:
      summary: Indicates the start of a response from the agent.
      payload:
        type: object
        properties:
          message:
            const: ResponseStarted
          content:
            type: string
            description: The content that is spoken by the agent in the response.
          start_time:
            type: number
            format: float
            description: The start time of the spoken response, relative to the start of the session.
        required:
          - message
          - content
          - start_time

    ResponseCompleted:
      summary: Indicates the completion of a response from the agent.
      payload:
        type: object
        properties:
          message:
            const: ResponseCompleted
          content:
            type: string
            description: The content that is spoken by the agent in the response.
          start_time:
            type: number
            format: float
            description: The start time of the spoken response, relative to the start of the session.
          end_time:
            type: number
            format: float
            description: The end time of the spoken response, relative to the start of the session.
        required:
          - message
          - content
          - start_time
          - end_time

    ResponseInterrupted:
      summary: Indicates that a response from the agent was interrupted.
      payload:
        type: object
        properties:
          message:
            const: ResponseInterrupted
          content:
            type: string
            description: The content that is spoken by the agent in the response.
          start_time:
            type: number
            format: float
            description: The start time of the spoken response, relative to the start of the session.
          end_time:
            type: number
            format: float
            description: The end time of the spoken response, relative to the start of the session.
        required:
          - message
          - content
          - start_time
          - end_time

    Info:
      summary: Additional information sent from the server to the client.
      payload:
        type: object
        properties:
          message:
            const: Info
          type:
            enum:
              - recognition_quality
              - model_redirect
              - deprecated
          reason:
            type: string
          code:
            type: integer
          seq_no:
            type: integer
          quality:
            type: string
        required:
          - message
          - type
          - reason

    Warning:
      summary: Warning messages sent from the server to the client.
      payload:
        type: object
        properties:
          message:
            const: Warning
          type:
            enum:
              - duration_limit_exceeded
          reason:
            type: string
          code:
            type: integer
          seq_no:
            type: integer
          duration_limit:
            type: number
        required:
          - message
          - type
          - reason

    Error:
      summary: Error messages sent from the server to the client.
      payload:
        type: object
        properties:
          message:
            const: Error
          type:
            enum:
              - invalid_message
              - invalid_model
              - invalid_config
              - invalid_audio_type
              - not_authorised
              - insufficient_funds
              - not_allowed
              - job_error
              - data_error
              - buffer_error
              - protocol_error
              - timelimit_exceeded
              - quota_exceeded
              - unknown_error
          reason:
            type: string
          code:
            type: integer
          seq_no:
            type: integer
        required:
          - message
          - type
          - reason

    ConversationEnding:
      summary: Indicates starting of the session transfer procedure
      payload:
        type: object
        properties:
          message:
            const: ConversationEnding
          reason:
            type: string
        required:
          - message

    ConversationEnded:
      summary: Server ends the conversation, after the server has finished sending all other messages.
      payload:
        type: object
        properties:
          message:
            const: ConversationEnded
        required:
          - message

  schemas:
    ConversationConfig:
      type: object
      required:
        - template_id
      properties:
        template_id:
          type: string
          description: The id of the agent or persona to use during the conversation.
        template_variables:
          type: object
          additionalProperties:
            type: string

    AudioFormat:
      type: object
      required:
        - type
      oneOf:
        - "$ref": "#/components/schemas/AudioFormatRaw"
        - "$ref": "#/components/schemas/AudioFormatFile"

    ToolConfig:
      type: object
      required:
        - type
        - function
      properties:
        type:
          type: string
          description: The type of the tool (currently, must be 'function').
          enum:
            - function
        function:
          type: object
          description: The function that the tool will call.
          required:
            - name
          properties:
            name:
              type: string
              description: The name of the tool.
            description:
              type: string
              description: A description of what the tool does.
            parameters:
              type: object
              properties:
                type:
                  type: string
                  description: The type of the parameters (currently, will always be object).
                required:
                  type: array
                  items:
                    type: string
                properties:
                  type: object
                  additionalProperties:
                    type: object
                    required:
                      - type
                    properties:
                      type:
                        type: string
                        description: The type of the parameter (e.g., string, integer, boolean).
                      description:
                        type: string
                        description: A description of the parameter.

    AudioFormatRaw:
      type: object
      title: "AudioFormatRaw"
      properties:
        type:
          enum:
            - raw
        encoding:
          enum:
            - pcm_f32le
            - pcm_s16le
            - mulaw
        sample_rate:
          type: integer
      required:
        - type
        - encoding
        - sample_rate

    AudioFormatFile:
      type: object
      title: "AudioFormatFile"
      properties:
        type:
          enum:
            - file
      required:
        - type

    TranscriptionConfig:
      type: object
      properties:
        language:
          type: string
        domain:
          type: string
          description: >-
            Request a specialized model based on 'language' but optimized for a particular field, e.g. "finance" or "medical".
        output_locale:
          "$ref": "#/components/schemas/OutputLocale"
        additional_vocab:
          "$ref": "#/components/schemas/VocabList"
        diarization:
          "$ref": "#/components/schemas/DiarizationConfig"
        max_delay:
          type: number
          minimum: 0
        max_delay_mode:
          "$ref": "#/components/schemas/MaxDelayModeConfig"
        speaker_diarization_config:
          "$ref": "#/components/schemas/SpeakerDiarizationConfig"
        audio_filtering_config:
          "$ref": "#/components/schemas/AudioFilteringConfig"
        transcript_filtering_config:
          "$ref": "#/components/schemas/TranscriptFilteringConfig"
        enable_partials:
          type: boolean
          default: false
        enable_entities:
          type: boolean
          default: true
        operating_point:
          "$ref": "#/components/schemas/OperatingPoint"
        punctuation_overrides:
          "$ref": "#/components/schemas/PunctuationOverrides"

      required:
        - language

    OperatingPoint:
      type: string
      enum:
        - standard
        - enhanced

    PunctuationOverrides:
      type: object
      properties:
        permitted_marks:
          type: array
          description: "The punctuation marks which the client is prepared to accept in transcription output, or the special value 'all' (the default). Unsupported marks are ignored. This value is used to guide the transcription process."
          items:
            pattern: "^(.|all)$"
            type: string
        sensitivity:
          type: number
          description: "Ranges between zero and one. Higher values will produce more punctuation. The default is 0.5."
          format: float
          maximum: 1
          minimum: 0

    TranslationConfig:
      type: object
      properties:
        target_languages:
          type: array
          items:
            type: string
        enable_partials:
          type: boolean
          default: false
      required:
        - target_languages

    AudioEventsConfig:
      type: object
      properties:
        types:
          type: array
          items:
            type: string

    VocabList:
      type: array
      items:
        "$ref": "#/components/schemas/VocabWord"

    VocabWord:
      oneOf:
        - type: object
          properties:
            content:
              type: string
              minLength: 1
            sounds_like:
              type: array
              items:
                type: string
                minLength: 1
              minItems: 1
          required:
            - content
        - type: string
          minLength: 1

    DiarizationConfig:
      type: string
      enum:
        - none
        - speaker

    SpeakerDiarizationConfig:
      type: object
      properties:
        max_speakers:
          type: number
          format: integer
          minimum: 2
          maximum: 100

    AudioFilteringConfig:
      type: object
      properties:
        volume_threshold:
          type: number
          format: float
          minimum: 0
          maximum: 100

    TranscriptFilteringConfig:
      properties:
        remove_disfluencies:
          type: boolean

    OutputLocale:
      type: string
      minLength: 1

    RecognitionMetadata:
      type: object
      properties:
        start_time:
          type: number
          format: float
        end_time:
          type: number
          format: float
        transcript:
          type: string
      required:
        - start_time
        - end_time
        - transcript

    RecognitionResult:
      type: object
      properties:
        type:
          type: string
          enum:
            - word
            - punctuation
        start_time:
          type: number
          format: float
        end_time:
          type: number
          format: float
        channel:
          type: string
        attaches_to:
          type: string
          enum:
            - next
            - previous
            - none
            - both
        is_eos:
          type: boolean
        alternatives:
          type: array
          items:
            "$ref": "#/components/schemas/RecognitionAlternative"
        score:
          type: number
          format: float
          minimum: 0
          maximum: 1
        volume:
          type: number
          format: float
          minimum: 0
          maximum: 100
      required:
        - type
        - start_time
        - end_time

    RecognitionAlternative:
      type: object
      properties:
        content:
          type: string
        confidence:
          type: number
          format: float
        language:
          # Although language is technically optional removing language breaks the way adapters adds spaces and
          # language specific punctuation. This caused REQ-10454. The solution for Bellini was to add the language field
          # back in at the rt-worker level. The future work on this issue is written up in REQ-10633.
          type: string
        display:
          "$ref": "#/components/schemas/RecognitionDisplay"
        speaker:
          type: string
      required:
        - content
        - confidence

    RecognitionDisplay:
      required:
        - direction
      properties:
        direction:
          type: string
          enum:
            - ltr
            - rtl
    MaxDelayModeConfig:
      type: string
      enum:
        - flexible
        - fixed